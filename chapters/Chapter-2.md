# Fundamentos de networking

Si bien no hay nada en este capítulo que pueda incluirse directamente en el examen, sería un error suponer que no es necesario conocer este material para tener éxito en lo que se cubrirá en el resto de este libro, ya que así como en el examen. Es posible que pueda aprender a ejecutar herramientas, pero si tiene problemas con lo que está haciendo, no entenderá lo que está sucediendo sin tener una gran cantidad de material básico. Todo esto es material que solía estar en el examen y sigue siendo material que es importante comprender en profundidad para tener éxito como hacker ético.

Para comprender cómo funcionan las redes, puede resultar útil tener una comprensión conceptual de cómo encajan los protocolos. Existe un modelo conceptual utilizado para describir los protocolos de comunicación y sus funciones. Hay otra forma de describir estas funciones, a veces llamada modelo, pero es más un diseño arquitectónico construido. En este capítulo, cubriré tanto el modelo de interconexión de sistemas abiertos (OSI) como la arquitectura TCP/IP.

Se espera que comprenda las topologías de red. Las topologías son generalmente conceptuales y pueden usarse como una forma de organizar sistemas lógicamente para ver cómo están conectados. Esto nos iniciará en el camino de hablar sobre los elementos físicos de las redes, incluido cómo se abordan. En última instancia, cuando somos sistemas en red, queremos que puedan comunicarse entre sí. Para lograrlo, cada sistema debe tener una forma para que otros lo aborden. Como verá, cada sistema tendrá múltiples direcciones. Esto se refiere a los modelos mencionados anteriormente porque las diferentes direcciones son formas de comunicarse con las diferentes funciones en diferentes capas.

A medida que avancemos en las pilas de red desde los componentes físicos, comenzaremos a hablar sobre los protocolos con los que quizás esté más familiarizado: Protocolo de Internet (IP), Protocolo de control de transmisión (TCP) y Protocolo de datagramas de usuario (UDP). Estos serán los protocolos fundamentales de los que necesitará una comprensión sólida no solo para probar los sistemas, sino también para brindar orientación sobre cómo las empresas para las que trabaja pueden remediar las diferentes vulnerabilidades.

Un enfoque común para brindar servicios de tecnología de la información en las empresas, especialmente si los servicios están dirigidos a usuarios o clientes externos, es utilizar proveedores de servicios. La computación en la nube se puede utilizar como una implementación de este tipo de subcontratación. Hacer uso de estos proveedores de servicios y trabajar con organizaciones que les han proporcionado sistemas y servicios presenta algunos desafíos específicos para alguien que realiza evaluaciones de seguridad o pruebas de penetración. Esto significa que comprender cómo funcionan estos proveedores de servicios externos puede ser esencial.
### Modelos de comunicación
Accedemos a los sistemas a través de sus direcciones. El problema es que cada sistema tendrá varias direcciones. Es mejor separar estas direcciones en depósitos relacionados con la funcionalidad proporcionada por el protocolo al que pertenece cada dirección. El primer modelo de comunicación, desde el punto de vista del que hablaremos pero también desde el punto de vista de la historia, es decir, que esencialmente fue el primero, es más conceptual que estrictamente práctico. Continuaré con un modelo práctico.

Estos modelos de comunicaciones se dividen en capas y las capas se apilan una encima de la otra. Debido a que se muestra como una pila de niveles, a menudo escuchará que se hace referencia a ellos como pilas de red o pilas de protocolos. Un aspecto importante a considerar cuando se trata de estas pilas de red es que todas las capas están separadas y la funcionalidad es distinta. Cuando dos sistemas están hablando, cada uno tiene estas capas nocionales, y la capa C en el primer sistema solo puede hablar con la capa C, no con las capas B, A o D, en el segundo sistema. Esto se debe a que los protocolos de la capa C en ambos sistemas coinciden. Lo mismo ocurre con los demás protocolos. Como ejemplo, puede ver un conjunto de encabezados de red en la Figura 2.1. La capa/función que generó este conjunto de encabezados en el lado emisor solo puede ser leída por la misma capa/función en el lado receptor.

![](img/2.1.png)

A medida que analicemos los dos modelos de comunicaciones, hablaré no solo de las funciones que existen en cada capa, sino también de los protocolos que existen en cada capa. Cuando hayamos terminado, tendrá dos formas diferentes, pero no diferentes, de comprender cómo se comunican los protocolos entre sistemas y cómo se combinan los mensajes entre sistemas/aplicaciones.

Dividir las funciones de las comunicaciones de red en capas significa que las funciones están modularizadas. Esto significa que puede resultar fácil extraer un protocolo de la cadena e insertar otro. A través de Ethernet funcionan, por ejemplo, los mismos protocolos que los que viajan a través de SONET o Frame Relay. Todos estos distintos protocolos proporcionan las mismas capacidades, aunque de diferentes maneras. Esto funciona porque la funcionalidad de cada capa se abstrae, lo que significa que las capas pueden comunicarse entre sí sin necesidad de conocer los detalles porque se conoce la funcionalidad. Los protocolos individuales no necesariamente importan. Existen muchos protocolos diferentes para cada una de las capas, sin importar de qué modelo estemos hablando.
### Sistemas abiertos de interconexión
Antes de finales de la década de 1970, los sistemas de comunicaciones utilizaban protocolos propietarios, lo que hacía más difícil conceptualizar lo que estaba sucediendo. Cada protocolo definió diferentes comunicaciones de diferentes maneras. A finales de la década de 1970, la Organización Internacional de Normalización (ISO) inició un proceso para definir un conjunto de estándares de comunicación. La idea detrás de esto era permitir una mejor interoperabilidad entre proveedores. Si todas las funciones se desglosan conceptualmente, los puntos de la interfaz son más claros y, como tales, más fáciles de interactuar.

En 1978 se anunció un modelo inicial. Después de refinamientos, se publicó como modelo OSI. Si bien hubo preocupaciones sobre la complejidad de este modelo y la posibilidad de que fuera poco probable que se implementara, sigue siendo un modelo sólido para ayudar a referirse a los límites entre funciones dentro de una pila de red. El modelo OSI incluye siete capas. Al indicar una funcionalidad particular, los profesionales de la red pueden hacer referencia a la función por el número de capa. Veremos cómo funciona esto en breve.

La Figura 2.2 muestra las siete capas del modelo OSI, que se describirán con más detalle en breve. La parte inferior de la pila es la capa física, que avanza hacia arriba hasta que hablamos de protocolos utilizados directamente por las aplicaciones.

![](img/2.2.png)

Debido a que los mensajes comienzan a crearse desde la capa de Aplicación hacia abajo, comenzaremos a analizar cada una de las capas y sus funciones allí y avanzaremos hacia abajo. Sin embargo, por si sirve de algo, los diversos mnemotécnicos que se utilizan a menudo para ayudar a las personas a recordar las diferentes capas comienzan en la parte inferior. Por ejemplo, uno de mis alumnos sugirió una vez "Por favor, no toques el caimán mascota de Steve" para ayudar a recordar el orden. Pero eso es de abajo hacia arriba. De todos modos, si recuerdas cualquiera de los dos ordenes y luego recuerdas qué hace cada una de las capas, estarás en buena forma.

**Aplicación (Capa 7)** La capa de Aplicación es la más cercana al usuario final. Sin embargo, esto no significa que sea la aplicación en sí. Estamos hablando de protocolos. Los protocolos de la capa de aplicación gestionan las necesidades de comunicación de la aplicación. Pueden identificar recursos y gestionar la interacción con esos recursos. Por ejemplo, el Protocolo de transferencia de hipertexto (HTTP) es un protocolo de capa de aplicación. Se encarga de negociar recursos (páginas, etc.) entre el cliente y el servidor.

**Presentación (Capa 6)** La capa de Presentación es responsable de preparar los datos para la capa de Aplicación. Se asegura de que los datos que se entrega a la aplicación está en el formato adecuado para su consumo. Cuando los sistemas se comunican, puede haber desconexiones en el formato entre los dos puntos finales, y la capa de presentación se asegura de que los datos tengan el formato correcto. Como tal, los formatos de codificación de caracteres como el Código Estándar Americano para Intercambio de información (ASCII), Unicode y binario extendido. Todos los códigos de intercambio decimal codificados (EBCDIC) pertenecen a la capa de presentación. Además, se considera que el formato JPEG (Joint Photographic Experts Group) está en la capa de presentación.

**Sesión (Capa 5)** La capa de Sesión gestiona la comunicación entre los puntos finales cuando se trata de mantener la comunicación de las aplicaciones (el cliente o servidor). Las llamadas a procedimientos remotos (RPC) son un ejemplo de una función en la capa de sesión. Hay componentes del intercambio de archivos que también se encuentran en la capa de sesión, ya que es necesario que se lleve a cabo la negociación de la comunicación entre los puntos finales. La capa de Aplicación se encarga de administrar los recursos, mientras que la capa de Sesión se encarga de garantizar que los archivos, por ejemplo, se transmitan correctamente y se completen.

**Transporte (Capa 4)** La capa de Transporte se encarga de segmentar los mensajes para su transmisión. La capa de Transporte también se encarga de la multiplexación de la comunicación. Tanto TCP como UDP son protocolos de transporte. Estos protocolos utilizan puertos para el direccionamiento, de modo que los sistemas receptores sepan a qué aplicación pasar el tráfico.

**Red (Capa 3)** La capa de Red recibe mensajes de un punto final a otro. Lo hace encargándose del direccionamiento y el enrutamiento. IP es un protocolo que existe u opera en esta capa.

**Enlace de datos (Capa 2)** Otra dirección con la que lidiar es la dirección de control de acceso a medios (MAC). Esta es una dirección de capa 2, que identifica la interfaz de red en la red para que las comunicaciones puedan pasar de un sistema a otro en la red local. La resolución de dirección
El protocolo (ARP), las redes de área local virtual (VLAN), Ethernet y Frame Relay son protocolos de capa de enlace de datos. Se encargan de formatear los datos que se enviarán en el medio de transmisión.

**Física (Capa 1)** Esta capa probablemente habla por sí sola. Se trata de todos los protocolos que gestionan las comunicaciones físicas. 10BaseT, 10Base2, 100BaseTX y 1000BaseT son ejemplos de protocolos de capa física. Ellos dictan cómo se manejan los pulsos en el cable.

Uno de los problemas con el modelo OSI es que no siempre hay buenos ajustes cuando se trata de asignar protocolos a las siete capas. El problema suele surgir en las áreas entre las capas de Sesión y Aplicación. Por ejemplo, ¿en qué capa se encuentra el protocolo Secure Shell (SSH)? ¿Es la capa de sesión porque en última instancia gestiona las sesiones, o es la capa de presentación porque incluye mecanismos de cifrado y los negocia? Parecen existir otros protocolos entre capas. Se dice que ARP, por ejemplo, opera en la capa de enlace de datos, pero necesita conocer la capa de red porque proporciona el puente entre el direccionamiento en esas dos capas.

Sin embargo, hay lugares donde tener el modelo facilita mucho la conceptualización de las cosas. Por ejemplo, probablemente tengas un dispositivo en tu casa que resulte muy confuso. Puede llamarlo enrutador o puede que conozca personas que lo llamen enrutador. El problema es que el enrutamiento es una función de capa 3, como se discutió anteriormente, y hay otras funciones en el dispositivo que son estrictamente de capa 2, lo que significa que tiene puertos de conmutador que transmiten mensajes en su red local donde no hay enrutamiento involucrado. Además, es muy posible que su dispositivo ni siquiera esté realizando ningún enrutamiento, sino que esté haciendo un puente con la red de su proveedor. Todo depende de cómo esté funcionando su dispositivo y de lo que su proveedor espera de su dispositivo. Aquí es donde resulta útil comprender las diferentes capas. Puede identificar mejor dónde puede tener problemas porque puede aislar la funcionalidad.
### Arquitectura TCP/IP
A finales de la década de 1960, se desarrolló e implementó por primera vez ARPANET. En los años siguientes, creció mucho más allá de los dos y luego tres nodos iniciales que se conectaron en 1968-1969. A medida que se conectaron más sistemas a la red, las personas responsables de gestionar la red y desarrollar los protocolos utilizados para intercambiar información aprendieron mucho. El protocolo inicial fue el protocolo 1822 que definía las comunicaciones con el Procesador de mensajes de interfaz (IMP), que era una computadora grande con interfaces especializadas que actuaba como puerta de enlace de mensajes (considérelo como un enrutador muy primitivo). Posteriormente, el protocolo 1822 fue reemplazado por el Programa de control de red (NCP).

En 1983, después de muchos años de desarrollo, el NCP fue reemplazado por completo por un conjunto de protocolos que ahora se denominan comúnmente Protocolo de control de transmisión (TCP)/Protocolo de Internet (IP). La forma en que se describe el conjunto de protocolos utilizados dentro de la pila TCP/IP es ligeramente diferente de la forma en que se describe el modelo OSI. Una vez implementado TCP/IP, se describió el diseño conceptual de los protocolos. Por esta razón, a veces se hace referencia a la suite como modelo, pero también se puede denominar arquitectura, ya que es una descripción de un diseño construido más que algo conceptual. OSI es completamente conceptual ya que no describe nada en particular.

La arquitectura TCP/IP es un diseño mucho más simple que el modelo OSI, lo cual es una diferencia inmediata y un reflejo de la naturaleza construida del diseño en comparación con el diseño conceptual de OSI. Dado que el modelo OSI tenía que ser abstracto y flexible para adaptarse a una amplia variedad de protocolos y diseños, se dividió en las siete categorías funcionales descritas anteriormente. TCP/IP, por otro lado, como definición tal como está construida, tiene solo cuatro capas.

Esto no quiere decir que no exista correlación entre el modelo OSI y la arquitectura TCP/IP. Como puede ver en la Figura 2.3, hay muchas similitudes entre los dos.

![](img/2.3.png)

Notarás las similitudes. Para empezar, hay una capa de Aplicación en ambos. También hay una capa de Transporte. Las capas de Internet y Red reciben nombres muy similares. Básicamente, lo que sucede es que las capas de sesión, presentación y aplicación del modelo OSI se contraen en la capa de aplicación en el modelo TCP/IP. Además, las capas Física y de Enlace de Datos del modelo OSI se contraen en la capa de Enlace en el modelo TCP/IP. Las mismas funciones de las capas colapsadas existen en el modelo TCP/IP. Sin embargo, conceptualmente es más fácil de entender. Todo lo relacionado con la comunicación de la aplicación, incluida la gestión de sesiones y el formato de datos, se encuentra en la capa de Aplicación. De manera similar, en el modelo TCP/IP, la capa física y la capa de enlace de datos están juntas.

Independientemente del modelo en el que prefiera pensar en la creación de redes, encontrará que los protocolos generalmente no se extienden a lo largo de múltiples capas. Están diseñados para cumplir con los requisitos de una función específica, que aterrizará bastante directamente en una de las capas de cada modelo.

En el resto del capítulo, y según mi experiencia, es bastante común en el mundo real, cuando ve una referencia a capas, la referencia es al modelo OSI y no a la arquitectura TCP/IP.
### Topologías
La forma en que se diseñan las redes también utiliza modelos conceptuales, como una forma de tomar un laberinto de redes físicas y mapearlas en una representación lógica. No se trata sólo de obtener un mapa lógico de la red, sino que también ayuda a identificar cómo está conectado todo, ya que ayudará a aislar posibles problemas. Las diferentes topologías introducen diferentes problemas potenciales. También encontrará normalmente que algunas topologías solo se encuentran en determinadas situaciones. Algunos se encontrarán en redes de proveedores de servicios, mientras que otros se encuentran más comúnmente en redes de área local.

Incluso en los casos en los que trabaje con redes virtuales, estas formas conceptuales de pensar sobre cómo se interconectan los sistemas le resultarán útiles. Al final, ya sea que esté conectando máquinas virtuales, contenedores, sistemas físicos o una colección de todos ellos, trabajará con uno de estos modelos de topología. La topología le indica cómo fluye el tráfico de un sistema a otro y por qué dispositivos intermediarios pasa la comunicación, lo que le ayudará a determinar dónde puede interceptar o manipular el tráfico.
### Red de bus
Una red de bus, como se muestra en la Figura 2.4, consta de un único cable de red al que se conectan todos los dispositivos de la red. Un autobús es un canal de comunicación. Es posible que encuentre un bus dentro de su computadora para comunicarse entre canales. En nuestro caso, se trata de un canal de comunicación (un único cable de red) que permite la comunicación entre varios ordenadores. La forma en que funcionan algunas redes de bus es mediante el uso de un cable coaxial con conectores en T. El Tconnector proporciona una forma de extraer la señal del bus para proporcionar conectividad a los sistemas de la red. Este tipo de red de bus requiere algo en el extremo del cable para mantener la señal en el cable. Estos dispositivos eléctricos se llaman terminadores. Puedes ver los bloques al final del autobús. Evitan que la señal se refleje en el cable, provocando la cancelación de la señal.

Lo que notará en la red de autobuses es que no hay ningún dispositivo mediador. Todos los ordenadores están conectados directamente entre sí mediante ese único cable de red.

![](img/2.4.png)

### Red estrella
Cuando vea un diagrama de una red en estrella, a menudo se verá similar a la red de autobuses. Sin embargo, la diferencia entre la red bus y la red en estrella es que existe un dispositivo mediador entre todos los dispositivos. Este puede ser un concentrador, si tiene una red muy antigua, que es un repetidor eléctrico tonto, o puede tener un interruptor. Puedes ver un diagrama tradicional en la Figura 2.5. En el caso de este diagrama, la línea central que ves, que parece un autobús, es en realidad un interruptor o un concentrador. Estos dispositivos luego enviarán las señales que ingresan a los otros dispositivos. En el caso de un hub, todos los dispositivos de la red lo recibirán. Si su red utiliza un conmutador, la señal se enviará al puerto correcto.

![](img/2.5.png)

Y aquí es donde las diferentes capas resultan útiles. Un conmutador, que es el dispositivo más común en una topología de red en estrella, actúa en la capa 2 del modelo OSI. Utiliza la dirección MAC para tomar decisiones sobre hacia dónde va el tráfico. En el caso de una red en estrella con un concentrador, existen los mismos problemas que habría con una red de bus: muchas colisiones en las que los mensajes enviados por cable chocan con otros mensajes enviados por otra persona. Un conmutador alivia esos problemas porque sólo el tráfico dirigido a un sistema se envía a ese sistema.
### Red de anillo
Una red en anillo es similar a una red de bus en el sentido de que todos los nodos de la red parecen estar conectados en un segmento de red contiguo. El tráfico pasa alrededor del anillo de un sistema a otro. Puede ver una representación lógica en la Figura 2.6. La razón por la que es una representación lógica es porque físicamente, no es así como están conectadas estas redes. Un tipo de red en anillo es un token ring. En una red Token Ring, los sistemas están cableados como si estuvieran en una estrella, utilizando unidades de acceso multiestación (MAU). Si bien están conectados de esa manera, no se comportan como una estrella. Aquí es donde debes recordar que se trata de modelos conceptuales. El comportamiento, independientemente del cableado, es como se nombran las topologías.

![](img/2.6.png)

Al igual que en una red de bus, también existe el problema de las colisiones. Una red Token Ring evita este problema mediante el uso de un bastón parlante. Al igual que cuando estás sentado alrededor de una fogata en una tribu aborigen, donde solo la persona con el bastón puede hablar, una red token ring utiliza una representación digital del bastón parlante llamado token. Sólo el sistema que tiene el token puede hablar. Si no hay ningún sistema que necesite enviar un mensaje, el token se pasa de un sistema a otro. Cuando un sistema necesita hablar, tiene que esperar a que le pasen el token. En teoría, esto evitará el problema de las colisiones, excepto que a veces el token se pierde, lo que significa que se debe generar un nuevo token. Después de que se genera el nuevo token, es posible que el antiguo token se "encuentre" nuevamente de repente, lo que significa que hay dos tokens en la red.

A pesar de que una red en anillo se comporta como una red de bus, no se necesitan terminadores como en una red de bus. El hardware necesario para que la red funcione como si estuviera en una configuración de anillo soluciona el problema de los ecos que regresan al cable.
### Red de malla
En otra topología, los sistemas están conectados directamente entre sí. La figura 2.7 muestra un ejemplo. Esto parece un poco como si estuvieran conectados en un anillo, pero es más como peer to peer. Para pasar de un sistema a otro, si no están conectados directamente entre sí, un sistema tiene que pasar a través de otro sistema. Las redes en malla normalmente evitarán otro problema potencial con una red de autobuses. Si falla un sistema en medio de la red de autobuses, existe la posibilidad de que falle toda la red junto con él. Básicamente, el sistema actúa como un terminador al no permitir que la señal eléctrica lo atraviese. Si un sistema en una red en malla falla, probablemente exista otro camino para llegar entre un sistema y otro.

![](img/2.7.png)

Si bien se pueden conectar sistemas entre sí de múltiples maneras en una red en malla, a pesar del orden que muestra el diseño circular de la red, un par de fallas pueden aislar potencialmente los nodos en una red en malla. La solución es agregar conexiones. Cuantas más vías haya para pasar de un sistema a otro, menos posibilidades habrá de que el fallo sea catastrófico, lo que significa que no se produce comunicación. Puede seguir agregando conexiones hasta que cada sistema tenga conexiones con todos los demás sistemas de la red. Puedes ver un ejemplo de este tipo de diseño en la Figura 2.8. Lo que ves en el diagrama es lo que se llama una red de malla completa. Cada sistema de la red tiene una conexión con todos los demás sistemas.

![](img/2.8.png)

El problema de agregar más conexiones es la complejidad resultante. Puedes ver un poco de eso. Diagramarlo hace que sea difícil ver dónde están todas las conexiones. Cada vez que agrega un nodo a la red, no agrega simplemente una única conexión. Agrega la misma cantidad de conexiones que nodos existentes, por lo que sus conexiones aumentan casi exponencialmente. De hecho, para determinar la cantidad de conexiones que tienes, puedes usar la fórmula n(n – 1)/2. Cada sistema tiene una conexión con todos los demás sistemas excepto con él mismo, por eso multiplicamos el número de sistemas por uno menos que el número de sistemas. (Por ejemplo, si tuvieras 5 sistemas, la fórmula se vería así 5(5 – 1)/2. Eso sería 5 * 4, que es 20, dividido por 2, lo que te da 10 conexiones). Dividimos por 2 porque No vamos en ambas direcciones, de un sistema a otro. Sólo necesitamos una única conexión.
### Híbrido
Cada una de las topologías anteriores es buena, dadas las circunstancias adecuadas. Sin embargo, hay circunstancias en las que combinar múltiples topologías de red es la forma correcta de conectar su red. Un enfoque híbrido común es el autobús estrella. Si tiene conmutadores con capacidad para 64 conexiones de red pero tiene 200 usuarios que necesita conectar a su red local, necesitará agregar efectivamente un bus a su topología de red. El bus conectaría todos sus conmutadores y se convertiría en la columna vertebral de su red. Luego, de cada interruptor, tienes la estrella tradicional donde todas las conexiones regresan al interruptor al que están conectadas. Esta no es una configuración de bus literal, donde todos los conmutadores están conectados a través de un bus. Sin embargo, podría diagramarlo de modo que cada conmutador parezca estar conectado a un bus, ya que todos pueden aparecer conectados como pares.

De manera similar, puede resultar útil conectar su infraestructura de conmutación en una malla o en un anillo. Esto puede ser por motivos de redundancia, para garantizar múltiples vías para llegar a toda su red. Si todo estaba en un bus y el bus falló, es posible que algunos segmentos de la red estén aislados. Como resultado, configurar su red con múltiples vías puede tener mucho sentido. Una red en malla o en anillo puede ayudar con eso.

Las redes híbridas son más comunes en el mundo físico, donde estamos sujetos a cables y equipos de red físicos. Esto es un problema menor en las redes virtuales, donde puede tener tantas interconexiones como admita su direccionamiento porque no está limitado por la cantidad de puertos en un conmutador o la cantidad de interfaces en su enrutador. Las redes virtuales proporcionan mucha flexibilidad y eliminan muchas limitaciones. Sin embargo, no todo sucede en el mundo virtual, ya sea en la nube o dentro de un hipervisor. Aún se encontrará con todos estos cables, conmutadores y enrutadores físicos.
### Redes físicas
En algún momento, necesitarás conectarte a la red. Hay múltiples componentes en esa interacción. Necesita una interfaz de red de su parte. Necesitas un medio que lleve la comunicación. Necesita tener algo al otro lado de la comunicación. Debido a que probablemente no trabajaremos con proveedores de servicios o proveedores de telecomunicaciones mientras realizamos pruebas de seguridad, al menos no en el lado del proveedor de la red, no nos preocuparemos por protocolos como Frame Relay, Modo de transferencia asincrónica. , o interfaz de datos distribuidos por fibra. El protocolo con el que se encontrará casi exclusivamente cuando hablemos de redes físicas es Ethernet.

Cada capa de la pila de red tiene un término diferente para referirse al fragmento de datos encapsulado por esa capa. Estos fragmentos se denominan unidades de datos de protocolo (PDU). La PDU en la capa 2, que es parte de lo que estamos hablando aquí, es una trama. Cuando miras un fragmento de datos que contiene la dirección física, estás mirando un marco. Hablaremos de los nombres de las otras PDU cuando lleguemos a esas capas.
### Direccionamiento
Todas las interfaces Ethernet tienen direcciones. Estas direcciones son exclusivas de cada interfaz de red y se denominan direcciones MAC. Debido a que la dirección MAC está codificada en el hardware de la interfaz, a veces se la denomina dirección de hardware. Dado que también es la dirección que utiliza una pieza física de hardware, a veces se la denomina dirección física.

El formato común de una dirección MAC es de 6 octetos (bytes de 8 bits) generalmente separados por dos puntos. Un ejemplo de dirección MAC sería BA:00:4C:78:57:00. La dirección se divide en dos partes. El primero es el identificador único organizacional (OUI). También se denomina ID del proveedor porque identifica el nombre de la empresa que fabricó la interfaz. La segunda mitad de la dirección MAC es la dirección única dentro del ID del proveedor de esa interfaz. Entonces, la mitad es para el proveedor y la otra mitad es para la tarjeta misma.

La dirección MAC se utiliza exclusivamente en su red local. Cualquier sistema que quiera enviarle algo lo dirigirá a su dirección MAC. También puede enviar mensajes a todos los dispositivos de la red utilizando la dirección de transmisión. La dirección MAC de transmisión es ff:ff:ff:ff:ff:ff. Su interfaz de red sabe qué dirección tiene porque está en el hardware. Sin embargo, lo que esto significa es que el tráfico que de alguna manera se dirige a la interfaz, ya sea directamente a su dirección o a la dirección de transmisión, por ejemplo, se reenviará al sistema operativo desde la interfaz de red. Todo lo demás será ignorado, a menos que se le indique específicamente a la interfaz que no lo ignore. Este sería un caso inusual, aunque es necesario para las capturas de paquetes.
### Switching
Las direcciones MAC son la piedra angular para la conmutación. El cambio es lo que sucede cuando las decisiones sobre el reenvío de mensajes se toman en función de la dirección física. Un conmutador es en realidad un puente multipuerto. Un puente es un dispositivo que conecta dos redes y pasa el tráfico entre ellas según la dirección MAC de destino. El tráfico local permanece a un lado del puente; se pasa por alto el tráfico destinado al otro lado. Sin embargo, esto significa que el conmutador necesita saber qué dirección MAC se encuentra en qué puerto. Lo hace esperando hasta que llegue un mensaje a cada puerto y observe la dirección de origen.

Debido a que tener que realizar una búsqueda de a qué puerto reenviar un mensaje lleva tiempo, lo que ralentizará la transmisión del mensaje, es esencial que la búsqueda sea lo más rápida posible. Esto generalmente se logra mediante el uso de algo llamado memoria direccionable por contenido (CAM). Esto significa que para buscar un valor, lo busca en función de otro valor. En lugar de una matriz de datos indexados con valores numéricos, lo que significa que buscamos un valor usando algo como la matriz para obtener el valor en el índice 5 de la matriz, usamos una dirección MAC como valor de índice. Esto significa que debe buscar entre todos los datos o mantenerlos ordenados para encontrar algo. Esto lleva mucho tiempo. Es más fácil buscar el valor de un puerto simplemente indexando la dirección MAC.

Lo que hace un conmutador, que es el valor de la conmutación, es determinar qué tráfico va a qué puerto en función de la dirección MAC de destino. Esto reduce la cantidad de tráfico que sale del puerto del switch y baja por el cable. Esto mejora el rendimiento porque puede llenar la conexión de red con tráfico específico del sistema conectado al puerto del conmutador en lugar de inundarla con todo el resto del tráfico de la red. Sin embargo, esto causa algunos otros problemas cuando se trata de pruebas de seguridad. En un entorno conmutado, solo verá el tráfico destinado a ese sistema conectado al puerto del conmutador. Al realizar pruebas de seguridad, actuando como un atacante, es más conveniente poder ver más tráfico que eso.

Hay algunas formas de solucionar ese desafío. Una de ellas, si tiene cierto control sobre el conmutador, es decirle al conmutador que refleje el tráfico de un puerto a otro. Luego, debe tener el sistema desde el que está ejecutando los ataques conectado al puerto espejo. Otra forma es engañar al switch para que le envíe tráfico, lo que implica métodos de ataque que cubriremos en capítulos posteriores.
### IP
Pasando a la capa de Red, nos encontramos con IP. Ciertamente, existen otros protocolos en la capa de red, como el Intercambio de paquetes entre redes (IPX), pero como Internet funciona con IP y sus protocolos asociados, nos centraremos allí. A medida que se pasa por cada capa, se agrega un conjunto de datos al mensaje que es específico del protocolo que procesa el mensaje. Estos conjuntos de datos se denominan encabezados. Cada protocolo tiene su propio conjunto de encabezados que se adjuntan. Luego, los encabezados encapsulan el mensaje, creando una PDU completamente nueva. Para IP, la PDU se denomina paquete. Es posible que escuche que se hace referencia a cada conjunto de datos en la red como paquete, pero desde un punto de vista técnico, un mensaje desde el encabezado IP hacia abajo es un paquete.

El abordaje también es algo a considerar. Este es un aspecto con el que las personas que trabajan con networking suelen estar bastante familiarizadas, pero es útil para entender qué comprende una dirección. Asociada con la dirección está la máscara de subred. Esto puede ser difícil de entender, pero existen algunos trucos matemáticos que pueden ayudar, una vez que los conozcas. También hay un par de formas diferentes de representar la máscara de subred y, a menudo, encontrarás ambas.

Actualmente hay dos versiones de IP en uso. La más común es la versión 4, comúnmente denominada IPv4. Hemos estado en el proceso de cambiar a la versión 6 durante las últimas dos décadas. Aún no hemos realizado la transición por completo, pero todos los dispositivos y sistemas operativos modernos admiten IPv6, por lo que verá la dirección IPv6 en la mayoría de los sistemas con los que interactuará. IPv6 tiene algunas diferencias en comparación con IPv4, una de las cuales es el tamaño del espacio de direcciones.

El IP se considera un protocolo de mejor esfuerzo. Hace todo lo posible para llevar los paquetes desde el origen al destino. No hace nada para garantizar absolutamente que lleguen allí. Sin embargo, facilita la transmisión al proporcionar direccionamiento.
### Encabezados
El Internet Engineering Task Force (IETF) es responsable de mantener toda la documentación relacionada con los protocolos. Cuando alguien, o más comúnmente un grupo de personas, quiere proponer un nuevo protocolo o una extensión de un protocolo existente, escribe algo llamado documento de solicitud de comentarios (RFC). El IETF no sólo mantiene los RFC, sino que también gestiona el proceso para su aprobación. El primer RFC se escribió en 1969 y estaba relacionado con el software anfitrión del IMP que se utilizaba para interconectar un sistema informático con ARPANET. En ese momento, por supuesto, el IETF no existía, pero el uso de RFC seguía siendo el proceso para crear especificaciones y estándares.

El RFC para IPv4, que se publicó en 1981, es 791. Define cómo se supone que funciona IPv4 y también define los campos de encabezado utilizados por IPv4. La Figura 2.9 muestra un conjunto de encabezados IPv4 de un mensaje capturado fuera de la red. Este es el mismo conjunto de encabezados que se presentarían en forma de tabla en el RFC al que se hace referencia. La diferencia entre el formulario de tabla y simplemente mirar los encabezados de esta manera es que con la tabla, puedes ver claramente el tamaño de cada campo de encabezado.

![](img/2.9.png)

Los siguientes son los campos de encabezado con sus descripciones y tamaños:
Versión Este campo indica qué versión de IPv4 está en este paquete. Este es un campo de 4 bits.

**Longitud** del encabezado Este campo indica cuántas palabras hay en el encabezado IPv4. Debido a que el encabezado se basa en palabras de 32 bits, que son 4 bytes, puede obtener el número de bytes multiplicando este valor por 4. En el caso de este ejemplo, encontrará que los encabezados son 20 bytes (cinco palabras ), que es común para un encabezado IP.

**Tipo de servicio** El RFC llama a esto el campo de tipo de servicio (ToS), aunque también verá que se lo conoce como campo de servicios diferenciados. Este campo ayuda a los elementos de la red a tomar decisiones sobre la calidad del servicio (QoS) al priorizar algunos mensajes y restar prioridad a otros. Este es un campo de 8 bits (1 byte).

**Longitud total** Esta es la longitud total del mensaje, incluido el encabezado IPv4 y cualquier dato posterior. Esto no incluye ningún encabezado que se agregue después del hecho, como el encabezado de la capa 2. Este campo tiene una longitud de 2 bytes, lo que permite una longitud total de mensaje de 65.535 octetos (bytes).

**Identificación** A veces se envían demasiados datos para caber en la longitud máxima permitida según el tamaño del campo de longitud. Esto significa que a veces es necesario fragmentar los mensajes. Todos los mensajes enviados tienen este campo configurado, aunque solo significa algo si hay fragmentos. Todos los fragmentos tendrán el mismo valor de identificación.

**Banderas** Hay 3 bits asignados a un campo de banderas. Uno está reservado y el segundo indica si el mensaje se puede fragmentar. A esto a veces se le llama bit DF. Si está configurado, significa que no fragmente el mensaje. El último bit se utiliza para indicar si hay fragmentos adicionales. Si está configurado, hay más fragmentos. Si no está configurado (es decir, 0), es el último fragmento. Un mensaje que sea autónomo, es decir, que no requiera ninguna fragmentación, tendría este aspecto claro.

**Desplazamiento de fragmento** El campo de desplazamiento de fragmento, de 13 bits de longitud, indica dónde se alinean los datos del paquete. Esto le permite al sistema receptor saber cómo unir todos los fragmentos. El valor de este campo está en palabras dobles u 8 octetos (bytes).

**Tiempo de vida** El campo de tiempo de vida (TTL) indica cuánto tiempo puede vivir un mensaje en la red antes de que se considere caducado. Está destinado a medirse en segundos, aunque cada dispositivo de red que toque el mensaje debe disminuir este campo. Dado que el paquete puede pasar a través de múltiples dispositivos de red en un segundo, la definición inicial de este campo ya no es relevante y el TTL realmente indica la cantidad de dispositivos de red (dispositivos de enrutamiento, esencialmente) por los que puede pasar el mensaje. Una vez que el campo llega a 0, el mensaje se descarta y se devuelve un mensaje de error al remitente. Este campo tiene una longitud de 8 bits.

**Protocolo** Este es un valor numérico que indica cuál es el siguiente protocolo. Es un campo de 8 bits y le dice al sistema receptor qué encabezados buscar en el encabezado de transporte. En el caso del paquete de la Figura 2.9, el valor es 17, lo que significa que es un mensaje UDP.

**Suma de comprobación** Este es un valor de 16 bits que se utiliza para determinar si el encabezado está intacto. Se define como una suma en complemento a 1 de las palabras de 16 bits en el encabezado.

**Dirección de origen** Esta es la dirección IPv4 que envió el mensaje. Tiene una longitud de 4 octetos.

**Dirección de destino** Esta es la dirección IPv4 a la que se dirige el mensaje. También tiene una longitud de 4 octetos.
### Direccionamiento
Las direcciones IP versión 4 tienen 4 octetos de longitud. Normalmente se muestran separados por un punto (.). Debido a esto, a veces se les llama cuadritos con puntos o notación decimal con puntos. Dado que cada valor tiene 8 bits, existen valores potenciales de 0 a 255. Sin embargo, no se utilizan todos los valores, especialmente en los dos primeros octetos. Hay algunas direcciones que se mantienen en reserva por diversos motivos. Para empezar, el rango de direcciones 127.0.0.0–127.255.255.255 está reservado para direcciones de loopback. Son direcciones que hacen referencia al host al que están asignadas. La interfaz loopback garantiza que siempre haya una interfaz de red en el sistema y permite realizar pruebas.

a través de una red sin enviar ningún tráfico fuera del sistema. Normalmente, la dirección de bucle invertido en los sistemas es 127.0.0.1, aunque se puede utilizar cualquier dirección en ese rango.

RFC 1918 también establece rangos de direcciones IP que se utilizan para redes privadas. Por convención, estas direcciones no se pueden enrutar a través de Internet. La mayoría de las redes harán algo para bloquear las direcciones de origen de estos rangos que ingresan a su espacio, ya que nunca deberían originarse desde el exterior de una red. Los rangos para estas direcciones privadas, destinadas a ser utilizadas por cualquier red que no tenga direcciones IP públicas, son 10.0.0.0–10.255.255.255, 172.16.0.0–172.31.255.255 y 192.168.0.0–192.168.255.255.

Además, se mantienen en reserva otros rangos de direcciones. El rango 224.0.0.0– a 239.255.255.255 se utiliza para mensajes de multidifusión. Todo lo que esté por encima de 240.0.0.0 también está reservado y no está en uso actualmente.

Una de las razones para pasar a IPv6 es la limitación de direcciones con la versión 4. Hay aproximadamente 4 mil millones de direcciones disponibles con IPv4. Sin embargo, esto incluye todo el conjunto de direcciones. De eso, eliminamos 16 millones de inmediato solo por el bloque de direcciones privadas 10.0.0.0. Luego, quitamos más de 268 millones debido a las direcciones superiores a 240.0.0.0. Puede ver lo rápido que desaparece el espacio de direcciones en IPv4. También habrás notado que la cantidad de dispositivos que se conectan a Internet está aumentando a un ritmo casi exponencial. La solución provisional para esto es utilizar rangos de direcciones privadas en el interior de las redes, especialmente las redes domésticas.

En lugar de sólo 4 octetos que se utilizan en IPv4, IPv6 utiliza 16 bytes. Debido a que sería complicado escribir un IPv6 en forma de octeto de puntos como lo hacemos con IPv4, las direcciones en IPv6 se escriben en una forma diferente. Debido a que un octeto se puede representar con dos dígitos hexadecimales, verá las direcciones IPv6 representadas de esa manera. Ahorra espacio y escritura. Dado que hay 16 octetos en una dirección IPv6, la dirección más larga con la que se encontrará tendrá 32 caracteres. Sin embargo, la dirección completa generalmente se separa en pares de bytes con dos puntos (:) entre ellos. Como ejemplo, uno de mis sistemas tiene una dirección IPv6 de fe80::62e3:5ec3:3e06:daa2.

Además de que la dirección se divide en pares de bytes, como fe80, notarás que hay una parte de la dirección que tiene un par de dos puntos sin nada intermedio. Esto no es un error. Esta es una abreviatura para indicar que lo que está en el medio son todos ceros. La dirección completa sería fe80:0000:0000:0000:62e3:5ec3:3e06:daa2. Es más fácil eliminar los 0 adicionales.

IPv6 tiene tres tipos de direcciones diferentes. El primero es unidifusión, que se refiere a un único sistema. Las direcciones Anycast son grupos de sistemas que comparten una única dirección. Un mensaje enviado a la dirección anycast se entregará solo a uno de los hosts del grupo anycast. Esta será normalmente la dirección más cercana, según las reglas de enrutamiento. Cualquier dirección anycast tendrá el mismo formato que una dirección unicast. Las direcciones de multidifusión se verán como las otras direcciones, pero su formato se basa en el hecho de que son direcciones de multidifusión y en la aplicación que utiliza la dirección. Es posible que vea una dirección de multidifusión como 224.0.0.1, por ejemplo.
### Subredes
La división en subredes puede ser un desafío de entender, pero es un concepto importante. Una de las razones por las que es importante es que es posible que necesite saber qué direcciones pertenecen a su objetivo según una subred. Si no establece correctamente los límites de la subred, existe la posibilidad de que comience a realizar pruebas en sistemas que no pertenecen a su objetivo. Esto puede causarle muchos problemas. Por eso, dedicaremos un poco de tiempo a hablar sobre qué son las subredes y cómo determinar los límites de las subredes. Esto implicará algunos cálculos simples, pero idealmente será fácil una vez que se lo explique.

Las direcciones IP se agregan en redes utilizando direcciones contiguas. Esto es relevante sin importar si hablamos de IPv4 o IPv6. Esto facilita el enrutamiento a esas direcciones, ya que las tablas de enrutamiento no tienen que realizar un seguimiento de cada dirección IP. En cambio, se realiza un seguimiento de los bloques agregados. En parte debido a esto, una parte de la dirección IP pertenece al host y otra pertenece a la red. Esta segmentación de la dirección también ayuda a los sistemas a saber qué direcciones son locales, es decir, las comunicaciones permanecen en la red local. La forma en que se les dice a los sistemas qué son redes locales y qué no son redes locales es emparejando una máscara de subred con la dirección IP.

La máscara de subred también tiene una longitud de 32 bits y se representa como un cuadrante de puntos en una dirección IPv4. Para determinar qué parte de una dirección IP pertenece a la red, observe los bits configurados en 1 en la máscara de subred. Para comprender mejor este concepto, veamos una representación binaria de una máscara de subred.

11111111.11111111.11111111.10000000

Cualquier posición de bit que tenga un 1 es parte del segmento de red. Notarás que los 1 se completan desde la izquierda y no hay espacios. Como resultado, las máscaras de subred sólo pueden tener ciertos valores: 0, 128, 192, 224, 240, 248, 252, 254 y 255. Esto se debe a que cada posición es una potencia de dos y sumamos desde el bit más significativo. En el lado izquierdo. El binario 10000000 equivale a 128 en decimal. 11000000 es 192. Cada vez que configuramos un bit en 1, sumamos la siguiente potencia inferior de 2. Al observar la máscara de subred de arriba y aplicar la traducción de binario a decimal, podemos ver que la máscara de subred es 255.255.255.128. Esto significa que sólo los últimos 7 bits del último octeto se utilizan para los valores del host. La representación de bits en el último octeto sería 10000000. Aquí es donde debemos comenzar a aplicar la dirección IP a la máscara de subred para obtener el rango de direcciones.

Con una máscara de subred de 255.255.255.128, tengo la posibilidad de dos bloques de direcciones, independientemente de cuál sea la dirección IP. Sólo puedo variar el último octeto y estoy limitado porque no puedo cambiar el valor en la posición del bit más significativo. Esto me deja con los rangos de 0 a 127 y de 128 a 255. Una vez que sé cuál es mi dirección IP, sé en qué bloque estoy. Digamos que mi dirección IP es 172.20.30.42 y mi máscara de red es 255.255.255.128. Sé que mi bloque de direcciones tiene que ser 172.20.30.0–127 porque ese es el rango en el que aterriza .42.

Otra forma de designar bloques de red es utilizar la notación CIDR (Classless Inter-Domain Routing). Esto significa que en lugar de indicar una máscara de subred, solo obtiene el número de bits de prefijo. El prefijo le indica qué bits se utilizan para la red. La máscara de subred utilizada anteriormente se traduce como /25, y yo indicaría la subred con la dirección IP indicando 172.20.30.42/25. Usar esta notación en realidad hace la vida un poco más fácil si lo piensas en potencias de dos.

Digamos que quieres saber cuántas direcciones pertenecen a un bloque de red en particular y tienes la notación CIDR. Una forma de tomar esa determinación es comenzar con una cantidad conocida. A menudo, verá notaciones CIDR flotando alrededor del área /24, que es una máscara de subred 255.255.255.0 y es común. Si desea saber cuántos hosts, simplemente divida por 2 o multiplique por 2 por cada cambio de bit en el prefijo. Una red que es /24 tiene 256 valores posibles en la parte del host (el último octeto). Si vas a /25, eso significa que obtienes 128 valores posibles (divídelos por 2 porque agregaste un bit de prefijo, lo que significa que perdiste un bit de host). Si va en la otra dirección a /23, duplicará porque perdió un bit de prefijo, lo que significa que se agregó a la parte del host. En lugar de 256, ahora tiene 512 valores posibles en la parte del host.

También puede ver con bastante rapidez cómo obtener valores de prefijo aún más pequeños simplemente observando el número de bits en cada octeto. Si el primer octeto se usa para la designación de red y todos los demás se usan para los valores del host, tendría todas las posiciones de bits en ese primer byte llenas, lo que significa que está usando 8 bits, dejándolo con una designación CIDR de / 8. De manera similar, si usa los dos primeros octetos, estará usando 16 bits, por lo que tendrá un /16.

Sin embargo, una nota sobre las subredes es que hay dos valores que no se pueden usar para los sistemas. Para la red se utiliza la dirección más baja posible en cualquier segmento de red. Para la dirección de transmisión se utiliza la dirección más alta posible en cualquier segmento de red. En una red /24 común, .0 se convierte en la dirección de red y .255 se utiliza para la transmisión. Ninguno de estos puede asignarse a los anfitriones.

IPv6 facilita aún más todo el proceso. Ya no se utilizan máscaras de subred al indicar una dirección de red. En cambio, la designación CIDR se utiliza exclusivamente para indicar qué parte es la red y cuál es el host. Se aplican las mismas reglas. La parte de la red siempre comienza desde la izquierda y completamos bits de la máscara desde la izquierda. Una red /50 significa que los primeros 50 bits de la dirección son la designación de la red. Esto deja los 78 bits restantes (tenga en cuenta que las direcciones IPv6 tienen 128 bits de longitud) para el host. Por supuesto, esa sería una red increíblemente grande.
### TCP
Pasando a la capa de Transporte, primero cruzamos el TCP. Mientras que IP es un protocolo de mejor esfuerzo, lo que significa que se hace el mejor esfuerzo para enviar mensajes de un sistema a otro, se dice que TCP tiene entrega garantizada. Esto quizá sea menos impresionante de lo que parece. Obviamente, TCP por sí solo no puede garantizar la entrega en caso de una falla catastrófica en la red. En cambio, lo que significa es que hay mecanismos en el protocolo que realizan un seguimiento de todos los mensajes que se envían, y si algo no llega al otro extremo y no se reconoce allí, los mensajes se reenviarán.

Las capas que hemos visto hasta ahora tienen formas de abordarse. La capa de Transporte no es diferente. Mientras que las direcciones anteriores están relacionadas con los sistemas para garantizar que los mensajes lleguen de un sistema a otro, en la capa de Transporte, comenzamos a preocuparnos por hacer llegar los mensajes a la aplicación. Los protocolos de la capa de transporte proporcionan puertos como una forma de abordar las aplicaciones. También proporcionan multiplexación. Sin puertos, no podríamos tener múltiples aplicaciones escuchando en el mismo sistema. Con los puertos tenemos una gran capacidad para conversaciones con otros sistemas.

Tal como hicimos con IP, veremos los encabezados definidos para TCP. TCP se define en RFC 793 y también se escribió en 1981, lo que significa que TCP existe desde hace mucho tiempo. Los encabezados permanecen sin cambios durante todo ese tiempo y, dado que los encabezados habilitan la funcionalidad del protocolo, la funcionalidad tampoco ha cambiado. La Figura 2.10 muestra los encabezados TCP de una captura de paquetes.

Verá los siguientes campos en la captura:
**Puerto de origen** El puerto de origen es el puerto desde el que se originó el tráfico en el lado emisor. Esto es importante porque las conversaciones no son unidireccionales. Para que el destinatario pueda responder, necesita un puerto al que enviar. Cuando se responde a los mensajes, los puertos de origen y destino se invierten. El puerto de origen tiene una longitud de 16 bits.

**Puerto de destino** El puerto de destino es el que está asociado con una aplicación. Cada conversación tiene un lado del cliente y un lado del servidor. El lado del servidor vincula una aplicación a un puerto de escucha. El cliente envía a este puerto como puerto de destino. Si el servidor envía desde el servidor al cliente, el puerto de destino es el puerto efímero asignado a la aplicación que se comunica con el servidor. El puerto de destino, al igual que el puerto de origen, tiene una longitud de 16 bits.

![](img/2.10.png)

**Número de secuencia** El número de secuencia es parte de lo que contribuye a la entrega garantizada. Este es un número de 32 bits que se establece en un valor aleatorio cuando se inicia la conversación. Se incrementa con el número de bytes que se envían. Usando el número de secuencia, el remitente le dice al destinatario en qué parte de la conversación cae este mensaje. Verá en el ejemplo que el número de secuencia se muestra como 0. La razón de esto es que el software de captura de paquetes muestra un 0 y luego presenta números de secuencia relativos, que son más fáciles de seguir.

**Número de confirmación** El número de confirmación está en el lado opuesto de la conversación del número de secuencia. Cuando el número de secuencia lo establece el remitente, el número de acuse de recibo lo establece el destinatario. El número de acuse de recibo se establece en el siguiente número de byte que el destinatario espera recibir. Lo que esto significa en la práctica es que el recuento de bytes se incrementa en 1 y luego se envía. Esto le dice al remitente en qué parte del flujo de comunicación se encuentra el destinatario, lo que le permite saber si se ha perdido algo en la transmisión.

**Desplazamiento de datos** El desplazamiento de datos es un valor de 4 bits que indica el número de palabras de 32 bits en el encabezado TCP. Le permite al sistema saber dónde buscar los datos. Esto es necesario porque el encabezado TCP puede tener una longitud variable. Este campo no se muestra en la figura, pero es un encabezado TCP definido.

**Reservado** Hay 6 bits en el encabezado TCP que están reservados para uso futuro.

**Bits de control** Hay 6 bits de bandera que se utilizan para indicar la disposición del mensaje. El indicador SYN es el indicador de sincronización, que indica que el número de secuencia está configurado y debe registrarse. El indicador ACK es el mismo para el número de acuse de recibo. La bandera URG indica que el puntero urgente tiene datos significativos. El indicador PSH es una indicación de que los datos deben enviarse hacia arriba en lugar de almacenarse en el búfer. El indicador RST restablece la conexión, lo que puede ocurrir si se recibe un mensaje que parece ser erróneo. El indicador FIN indica que la conversación terminó y no hay más datos para enviar.

**Ventana** El valor en el campo de la ventana le dice al destinatario cuántos bytes está dispuesto a aceptar el remitente. Esto permite acelerar y ralentizar la comunicación. Un tamaño de ventana más pequeño significa que se necesitan más confirmaciones, lo que puede ser una indicación de que el canal de comunicación no es confiable. Un tamaño de ventana más grande significa que el canal es confiable, por lo que no es necesario seguir registrando. El campo de la ventana es de 16 bits.

**Suma de comprobación** Este es un campo de 16 bits que se utiliza para garantizar que la comunicación no se haya dañado. Este es un valor en complemento a 1 calculado sobre los encabezados y el texto.

**Puntero urgente** El puntero urgente de 16 bits indica el siguiente valor de byte después de los datos urgentes. Esto se alinea con los valores del número de secuencia. Esencialmente, el puntero urgente dice los datos desde el número de secuencia actual hasta que el valor en el puntero urgente es datos urgentes.

**Opciones** Estos son campos de encabezado de longitud variable. El encabezado debe estar alineado con palabras de 32 bits. Si las opciones dejan la longitud del encabezado por debajo de esa alineación, se necesitan bits de relleno para llenar el resto del encabezado.

TCP utiliza múltiples mecanismos para garantizar un servicio confiable. La primera es que TCP está orientado a la conexión. Las conexiones se establecen mediante lo que se denomina un protocolo de enlace de tres vías. La Figura 2.11 muestra un diagrama del proceso de apretón de manos. El apretón de manos garantiza que ambas partes de la conversación estén vivas y activas porque se espera que respondan. El primer mensaje en el protocolo de enlace de tres vías es el mensaje SYN. Se establece el indicador SYN, así como el número de secuencia inicial, que es un valor aleatorio. La respuesta al mensaje SYN es un mensaje de reconocimiento. Esto establece el indicador ACK e incrementa el número de secuencia inicial en uno, lo que indica que se recibió el primer mensaje. En el mismo segmento, también se configuran el indicador SYN y el número de secuencia. Tenga en cuenta que la conversación es bidireccional, por lo que ambas partes deben realizar un seguimiento de dónde se encuentran en la conversación. Cada lado realiza un seguimiento de un número de secuencia para su lado y un número de acuse de recibo para el otro lado. El mensaje final en el protocolo de enlace es uno que solo tiene configurado el indicador ACK, y el campo de reconocimiento incrementa el número de secuencia establecido en el mensaje SYN/ACK.

![](img/2.11.png)

Dado que se espera que ambas partes respondan a los mensajes con información proporcionada por la otra, podemos estar seguros de que el mensaje fue recibido por la parte prevista y que ambas partes son quienes dicen ser, al menos en teoría. Si cualquiera de las partes intentara falsificar una conversación, no recibirían los mensajes y, como resultado, no responderían correctamente.

El siguiente mecanismo que ayuda a garantizar la confiabilidad es el número de secuencia. Dado que el número de secuencia mantiene la cantidad de bytes que se han enviado, el número de acuse de recibo le dice al remitente si falta algún dato durante la transmisión. Si es así, el remitente sabe que es necesario retransmitirlo. Cada lado de la conversación sabe dónde está y dónde está su interlocutor. TCP retransmite según sea necesario, hasta un máximo definido.

Además, los números de secuencia y acuse de recibo garantizan el orden correcto de los mensajes en el destinatario. Si los mensajes llegan desordenados, los números de secuencia indican si se deben retener los mensajes que se perdieron. Esto también es parte de la entrega garantizada: asegurarse de que los mensajes no solo lleguen como se esperaba, sino que también estén en el orden correcto cuando lleguen. Todo esto, sin embargo, conlleva gastos generales. No todas las aplicaciones necesitan el modelo de entrega garantizado que proporciona TCP.
### UDP
UDP ofrece otro modo de transporte que no tiene la misma sobrecarga que TCP. Es un protocolo mucho más liviano que no ofrece garantía de entrega. Los mensajes enviados mediante UDP simplemente se envían por cable con la esperanza de que lleguen al destino porque el protocolo de red, IP, se encargará de todo. Con el peso más liviano, se generan muy pocos gastos generales relacionados con cosas como establecer conexiones y asegurarse de que los mensajes lleguen a su destino. Tampoco importa mucho en qué orden se reciben los mensajes desde el punto de vista del protocolo. Si la aplicación está interesada en ese tipo de detalles, puede encargarse de la gestión.

El RFC para UDP es RFC 768. El RFC completo tiene poco más de dos páginas, lo que debería dejar claro lo simple que es el protocolo. Puede ver un ejemplo de un encabezado UDP en la Figura 2.12. Hay cuatro campos de encabezado. Todos ellos tienen 16 bits de longitud. Como era de esperar, la mitad de ellos son puertos de origen y de destino. Lo interesante de esto es que el puerto de origen se considera un campo opcional. La razón de esto es que, dado que no hay conexión, es posible que nunca haya una respuesta del servidor. Depende totalmente de la aplicación en uso, que es diferente de TCP. Se requiere un puerto de origen con TCP porque siempre habrá una respuesta, incluso si solo se usa para completar el protocolo de enlace de tres vías.

![](img/2.12.png)

Quizás sea interesante que RFC 768 no defina una respuesta a un puerto UDP cerrado. De hecho, no se mencionan los puertos cerrados. El único lugar donde se mencionan las respuestas a puertos cerrados que es relevante es en el RFC para el Protocolo de mensajes de control de Internet (ICMP). Incluso entonces, sólo hay un código para puerto inalcanzable. No hay ninguna indicación sobre el protocolo donde se aplica. Por este motivo, trabajar con puertos UDP no es nada fiable. Si no recibe una respuesta, podría deberse a la pérdida o caída de un paquete. Podría ser que la aplicación haya ignorado el mensaje. Podría ser que no se requiriera respuesta. Cualquiera de esos son escenarios legítimos en los que no obtendría una respuesta a un mensaje en un puerto UDP.

UDP es bueno para aplicaciones que requieren una configuración y transmisión rápidas. Por ejemplo, la transmisión de vídeo y audio funciona bien con UDP. No funcionan bien con TCP. Una razón importante para esto es que con UDP, depende de la aplicación reordenar los mensajes, según sea necesario. Si un datagrama (la PDU para UDP) no funciona con la transmisión de video, la aplicación simplemente lo descartará. Lo mismo ocurre con la transmisión de audio. Imagínese por un segundo si estuviera hablando con alguien a través de Internet. Saludaste a la persona al otro lado de la línea. En realidad, esa palabra probablemente se transmitiría en un solo mensaje, pero digamos que cada sonido de letra se transmitiera en su propio mensaje.

Si recibieras mensajes con los sonidos l, h, l, o y luego e, ¿cómo te sonaría? Nuestros cerebros son muy buenos para juntar los datos que faltan y construir algo que parezca completo, pero podría ser que tu cerebro no fuera capaz de encontrarle sentido a la palabra tal como suena. Incluso si tu cerebro pudiera entenderlo, sonaría extraño y tu experiencia general sería mala. Lo mismo ocurre con el vídeo, por supuesto. Si se insertaran las llegadas tarde en la transmisión de video que estás viendo, parecería muy nervioso.

¿Por qué los mensajes llegarían desordenados? Después de todo, hoy en día contamos con un servicio de Internet muy confiable. Bueno, hay varias razones por las que los mensajes no funcionan. Digamos que estás enviando un flujo de datos a alguien que usa UDP. Estás enviando tus datos por la ruta A âž¢ B âž¢ C âž¢ D, que es tu destino. Sin embargo, digamos que C cae justo cuando su mensaje está a punto de llegar. La red corrige y rodea C, tomando otro camino, tal vez A âž¢ E âž¢ F âž¢ D. Sin embargo, la falla ocurrió mientras al menos uno de sus mensajes estaba en tránsito y no tiene forma de saber que el mensaje estaba en circulación. acaba de caer debido a una falla. Incluso si no es una falla y los mensajes se descartan, podría ser que un mensaje tome una ruta y un mensaje posterior tome otra ruta, que resulta ser más rápida. El mensaje posterior puede llegar antes que el mensaje anterior. Hay muchas razones por las que los mensajes pueden llegar desordenados o incluso desaparecer por completo. En la red suceden muchas cosas de las que los usuarios no son conscientes. Es por eso que la mayoría de las aplicaciones dependen de TCP. La mayoría de las aplicaciones dependen de mensajes que se presentan en el orden correcto. Los protocolos en tiempo real se preocupan menos por el orden correcto, por lo que utilizan UDP.

### Protocolo de mensajes de control de Internet
El ICMP es un caso especial cuando se trata de protocolos, ya que no transporta datos del usuario. En cambio, funciona con otros protocolos para proporcionar mensajes de error y control. Cuando sucede algo inesperado en la red, los dispositivos generarán mensajes ICMP para enviarlos al dispositivo de origen para informarles que hubo un problema. Se encuentra encima de IP, porque necesita el direccionamiento de IP, pero se considera parte de la capa de Internet al igual que IP. Esto también lo convierte en un protocolo un poco inusual, porque en cierto modo se encuentra por encima de la capa de red pero no es un protocolo de capa de transporte.

ICMP se define en RFC 792, que especifica un encabezado de 8 bytes. Consiste en los campos de tipo y código, que transmiten la información esencial para ICMP, un campo de suma de verificación y luego 4 bytes etiquetados como "resto del encabezado". El tipo y el código son cada uno de un byte y la suma de verificación es de 2 bytes. El resto del campo del encabezado contiene datos relacionados con el tipo y código. El tipo y el código definen lo que cabe en esos 4 bytes.

El tipo de mensaje indica el mensaje que se envía. Puede tener valores que se refieren a mensajes de respuesta de eco, solicitud de eco, destino inalcanzable, extinción de origen o marca de tiempo. Cada tipo puede tener múltiples subtipos. Los diferentes subtipos se especifican en el campo de código. Por ejemplo, el tipo de destino inalcanzable tiene códigos que indicarían exactamente cuál es el destino. Puede ser una red, un host o un puerto. Puede indicar que son inalcanzables o puede indicar que el mensaje que activó el mensaje ICMP estaba prohibido administrativamente.

Cualquiera que realice pruebas de seguridad o pruebas de penetración se encontrará con mayor frecuencia con mensajes ICMP mediante el uso de mensajes de solicitud de eco y respuesta de eco ICMP. Estos son utilizados por el programa ping. También puede utilizar el programa traceroute para obtener la ruta de la red a un destino. El programa traceroute se basa en dos mensajes ICMP. El primero es ICMP tipo 11, que es tiempo excedido en tránsito. Esto significa que el campo TTL del mensaje se redujo a cero. Cuando se completa el traceroute, el programa espera recibir un mensaje ICMP tipo 3, destino inalcanzable, probablemente con el código 3, que significa puerto de destino inalcanzable. Esto depende, en parte, de la implementación de traceroute. Esto supone el uso de mensajes TCP con un puerto de destino.
### Arquitecturas de red
Hemos hablado de topologías y son útiles para obtener representaciones conceptuales y lógicas de su red. Sin embargo, también existe un contexto más amplio para la red. Combinar la topología con los flujos de datos y otros elementos de la red le dará una arquitectura de red. Esto describe los protocolos que se utilizan y dónde se utilizan, y también puede obtener enclaves de seguridad como parte de una arquitectura de red. También tendrás que lidiar con la idea de múltiples ubicaciones.

Desde una perspectiva de seguridad, hay otros elementos a considerar, incluido el aislamiento. Esto puede significar categorizar los sistemas según su uso y riesgo. Algunos sistemas, especialmente aquellos que necesitan estar directamente frente a Internet (lo que significa que los usuarios externos realizarán conexiones de red a esos sistemas como parte normal de su operación) pueden mantenerse separados y protegidos de los sistemas donde se encuentran los usuarios o incluso donde se almacenan datos confidenciales. 